{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local setup, not needed in cluster\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"standardization_notebook\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get some data\n",
    "%%bash\n",
    "for i in `seq 2000 2016`; do\n",
    "    wget https://www1.ncdc.noaa.gov/pub/data/ghcn/daily/by_year/${i}.csv.gz\n",
    "    gzip -cd ${i}.csv.gz  | grep -e TMIN -e TMAX | grep ^US > ${i}.csv\n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move to HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual code\n",
    "from __future__ import print_function\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkdf(filename):\n",
    "    df = spark.read.format(\"csv\").option(\"header\", \"false\").load(filename)\n",
    "    df = df.selectExpr(\n",
    "        \"_c0 as station\",\n",
    "        \"_c1 as date\",\n",
    "        \"_c2 as measurement\",\n",
    "        \"_c3 as degree\",\n",
    "        \"_c4 as m\",\n",
    "        \"_c5 as q\",\n",
    "        \"_c6 as s\",\n",
    "        \"_c7 as time\",\n",
    "    )\n",
    "    df = df.filter(\"q is null\") # Quality only\n",
    "    df = df.filter(\"s==0\") # USA only\n",
    "    df = df.filter(\"degree is not null\")\n",
    "    df = df.withColumn(\"degree\", df['degree'].cast(IntegerType()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+-----------+------+----+----+---+----+\n",
      "|    station|    date|measurement|degree|   m|   q|  s|time|\n",
      "+-----------+--------+-----------+------+----+----+---+----+\n",
      "|USC00027281|20080101|       TMAX|   156|null|null|  0|0700|\n",
      "|USC00027281|20080101|       TMIN|     0|null|null|  0|0700|\n",
      "|USC00034988|20080101|       TMAX|   133|null|null|  0|0700|\n",
      "|USC00034988|20080101|       TMIN|   -44|null|null|  0|0700|\n",
      "|USC00093578|20080101|       TMAX|   178|null|null|  0|0800|\n",
      "|USC00093578|20080101|       TMIN|    44|null|null|  0|0800|\n",
      "|USC00109601|20080101|       TMAX|   -89|null|null|  0|1800|\n",
      "|USC00109601|20080101|       TMIN|  -239|null|null|  0|1800|\n",
      "|USC00110187|20080101|       TMIN|   -83|null|null|  0|1600|\n",
      "|USC00419361|20080101|       TMAX|   250|null|null|  0|0800|\n",
      "|USC00419361|20080101|       TMIN|    44|null|null|  0|0800|\n",
      "|USC00421168|20080101|       TMAX|     0|null|null|  0|0800|\n",
      "|USC00421168|20080101|       TMIN|  -150|null|null|  0|0800|\n",
      "|USC00426568|20080101|       TMAX|  -189|null|null|  0|1600|\n",
      "|USC00426568|20080101|       TMIN|  -306|null|null|  0|1600|\n",
      "|USC00455704|20080101|       TMAX|    67|null|null|  0|0800|\n",
      "|USC00455704|20080101|       TMIN|   -11|null|null|  0|0800|\n",
      "|USC00470645|20080101|       TMAX|   -22|null|null|  0|0800|\n",
      "|USC00470645|20080101|       TMIN|  -122|null|null|  0|0800|\n",
      "|USW00003889|20080101|       TMAX|    94|null|null|  0|0700|\n",
      "+-----------+--------+-----------+------+----+----+---+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "root\n",
      " |-- station: string (nullable = true)\n",
      " |-- date: string (nullable = true)\n",
      " |-- measurement: string (nullable = true)\n",
      " |-- degree: integer (nullable = true)\n",
      " |-- m: string (nullable = true)\n",
      " |-- q: string (nullable = true)\n",
      " |-- s: string (nullable = true)\n",
      " |-- time: string (nullable = true)\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = mkdf('2*.csv')\n",
    "print(df.show())\n",
    "print(df.printSchema())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "## Numerical standardization across levels of categories\n",
    "- Pretend these are temperatures on a given location and station indicates the machine id/location (top of furnace #17 for instance)\n",
    "- S here represents a location, let's pretend those are different parts of a machine and need to be normalized independelty\n",
    "- The transformation and count take around 1 minute on a macbook over 43 million rows\n",
    "\n",
    "Note that groupBy statements have terrible scaling properties and should be avoided if at all possible. This method requires a shuffle due to the fact that we need aggregates within each partition window for each data element. \n",
    "\n",
    "The following method isn't neccessary if we do not need to work by partition but instead work on the entire DataFrame. If this was the case we would use built-in methods such as MinMaxScaler, StandardScaler, Normalizer (https://spark.apache.org/docs/2.1.1/ml-features.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(c, w):\n",
    "    return (col(c) - F.mean(c).over(w)) / F.stddev(c).over(w)\n",
    "\n",
    "def min_max(c, w):\n",
    "    return (col(c) - F.min(c).over(w)) / (F.max(c).over(w) - F.min(c).over(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['station','s']\n",
    "target = \"degree\"\n",
    "w = Window.partitionBy(*categories)\n",
    "\n",
    "df_transformed = df.select(\n",
    "    z_score(target,w).alias(\"{0}_normalized\".format(target)),\n",
    "    min_max(target,w).alias(\"{0}_min_max\".format(target)),\n",
    "    *categories\n",
    ")\n",
    "df_transformed = df_transformed.withColumn(\"id\", F.monotonically_increasing_id())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----------+---+---+\n",
      "|   degree_normalized|     degree_min_max|    station|  s| id|\n",
      "+--------------------+-------------------+-----------+---+---+\n",
      "| -1.1693525883416795|0.25504587155963304|USC00026180|  0|  0|\n",
      "|  -1.910720122784184|0.09174311926605505|USC00026180|  0|  1|\n",
      "| -1.1193727545590386|0.26605504587155965|USC00026180|  0|  2|\n",
      "| -1.7691105937333684|0.12293577981651377|USC00026180|  0|  3|\n",
      "|  -1.027743059290864|0.28623853211009176|USC00026180|  0|  4|\n",
      "| -1.8190904275160094|0.11192660550458716|USC00026180|  0|  5|\n",
      "| -0.3780052201165342|0.42935779816513764|USC00026180|  0|  6|\n",
      "| -1.5358713694143784| 0.1743119266055046|USC00026180|  0|  7|\n",
      "| -0.3780052201165342|0.42935779816513764|USC00026180|  0|  8|\n",
      "| -1.4025918126606696| 0.2036697247706422|USC00026180|  0|  9|\n",
      "|-0.42798505389917496|0.41834862385321103|USC00026180|  0| 10|\n",
      "|  -1.027743059290864|0.28623853211009176|USC00026180|  0| 11|\n",
      "| -0.7945038349718738| 0.3376146788990826|USC00026180|  0| 12|\n",
      "| -1.2110024498272134|0.24587155963302754|USC00026180|  0| 13|\n",
      "|  -1.027743059290864|0.28623853211009176|USC00026180|  0| 14|\n",
      "|  -1.585851203197019|  0.163302752293578|USC00026180|  0| 15|\n",
      "| -0.6112444444355244| 0.3779816513761468|USC00026180|  0| 16|\n",
      "| -1.5358713694143784| 0.1743119266055046|USC00026180|  0| 17|\n",
      "| -0.7945038349718738| 0.3376146788990826|USC00026180|  0| 18|\n",
      "| -1.4942215079288443| 0.1834862385321101|USC00026180|  0| 19|\n",
      "+--------------------+-------------------+-----------+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "None\n",
      "43701863\n"
     ]
    }
   ],
   "source": [
    "df_transformed.cache()\n",
    "df_transformed.show()\n",
    "print(df_transformed.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryTableScan [degree_normalized#2534, degree_min_max#2538, station#1176, s#1182, id#2575L]\n",
      "   +- InMemoryRelation [degree_normalized#2534, degree_min_max#2538, station#1176, s#1182, id#2575L], true, 10000, StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *Project [((cast(degree#1196 as double) - _we0#1367) / _we1#1368) AS degree_normalized#1336, (cast((degree#1196 - _we2#1369) as double) / cast((_we3#1370 - _we4#1371) as double)) AS degree_min_max#1340, station#1176, s#1182, monotonically_increasing_id() AS id#1377L]\n",
      "            +- Window [avg(_w1#1357L) windowspecdefinition(station#1176, s#1182, ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS _we0#1367, stddev_samp(_w2#1358) windowspecdefinition(station#1176, s#1182, ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS _we1#1368, min(degree#1196) windowspecdefinition(station#1176, s#1182, ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS _we2#1369, max(degree#1196) windowspecdefinition(station#1176, s#1182, ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS _we3#1370, min(degree#1196) windowspecdefinition(station#1176, s#1182, ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING) AS _we4#1371], [station#1176, s#1182]\n",
      "               +- *Sort [station#1176 ASC NULLS FIRST, s#1182 ASC NULLS FIRST], false, 0\n",
      "                  +- Exchange hashpartitioning(station#1176, s#1182, 200)\n",
      "                     +- *Project [_c0#1159 AS station#1176, _c6#1165 AS s#1182, cast(_c3#1162 as int) AS degree#1196, cast(cast(_c3#1162 as int) as bigint) AS _w1#1357L, cast(cast(_c3#1162 as int) as double) AS _w2#1358]\n",
      "                        +- *Filter (((isnull(_c5#1164) && isnotnull(_c6#1165)) && (cast(_c6#1165 as double) = 0.0)) && isnotnull(_c3#1162))\n",
      "                           +- *FileScan csv [_c0#1159,_c3#1162,_c5#1164,_c6#1165] Batched: false, Format: CSV, Location: InMemoryFileIndex[file:/Users/james.m.york-winegar/2008.csv, file:/Users/james.m.york-winegar/200..., PartitionFilters: [], PushedFilters: [IsNull(_c5), IsNotNull(_c6), IsNotNull(_c3)], ReadSchema: struct<_c0:string,_c3:string,_c5:string,_c6:string>\n"
     ]
    }
   ],
   "source": [
    "df_transformed.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Normalization\n",
    "\n",
    "We do fuzzy matching based off sound distance and lexiconical distance, both of which are directly available from Spark's API. Other methods would require a User-Defined Function (UDF) which has terrible scaling properties, but if needed for accuracy could be developed. BDCSCE supports Spark 2.1 instead of the more modern Spark versions 2.3+ which allow for vectorized calculations (Pandas UDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "department1 = Row(id='123456', name='Computer Science')\n",
    "department2 = Row(id='789012', name='Mechanical Physics')\n",
    "department3 = Row(id='345678', name='Theater and Drama')\n",
    "department4 = Row(id='901234', name='recreation')\n",
    "department5 = Row(id='123457', name='Computer tech')\n",
    "department6 = Row(id='789013', name='Mechanical Physical')\n",
    "department7 = Row(id='345679', name='Theater and drame')\n",
    "department8 = Row(id='901235', name='Recreatin')\n",
    "\n",
    "departments = [\n",
    "    department1,\n",
    "    department2,\n",
    "    department3,\n",
    "    department4,\n",
    "    department5,\n",
    "    department6,\n",
    "    department7,\n",
    "    department8\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df = spark.createDataFrame(departments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|    id|               name|\n",
      "+------+-------------------+\n",
      "|123456|   Computer Science|\n",
      "|789012| Mechanical Physics|\n",
      "|345678|  Theater and Drama|\n",
      "|901234|         recreation|\n",
      "|123457|      Computer tech|\n",
      "|789013|Mechanical Physical|\n",
      "|345679|  Theater and drame|\n",
      "|901235|          Recreatin|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|              name1|\n",
      "+-------------------+\n",
      "|          Recreatin|\n",
      "| Mechanical Physics|\n",
      "|         recreation|\n",
      "|Mechanical Physical|\n",
      "|  Theater and Drama|\n",
      "|  Theater and drame|\n",
      "|   Computer Science|\n",
      "|      Computer tech|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distinct_names = cat_df.selectExpr('name as name1').distinct().cache()\n",
    "distinct_names.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------+\n",
      "|             name1|              name2|\n",
      "+------------------+-------------------+\n",
      "|         Recreatin|          Recreatin|\n",
      "|         Recreatin| Mechanical Physics|\n",
      "|         Recreatin|         recreation|\n",
      "|         Recreatin|Mechanical Physical|\n",
      "|         Recreatin|  Theater and Drama|\n",
      "|         Recreatin|  Theater and drame|\n",
      "|         Recreatin|   Computer Science|\n",
      "|         Recreatin|      Computer tech|\n",
      "|Mechanical Physics|          Recreatin|\n",
      "|Mechanical Physics| Mechanical Physics|\n",
      "|Mechanical Physics|         recreation|\n",
      "|Mechanical Physics|Mechanical Physical|\n",
      "|Mechanical Physics|  Theater and Drama|\n",
      "|Mechanical Physics|  Theater and drame|\n",
      "|Mechanical Physics|   Computer Science|\n",
      "|Mechanical Physics|      Computer tech|\n",
      "|        recreation|          Recreatin|\n",
      "|        recreation| Mechanical Physics|\n",
      "|        recreation|         recreation|\n",
      "|        recreation|Mechanical Physical|\n",
      "+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "64\n"
     ]
    }
   ],
   "source": [
    "distinct_name_pairs = distinct_names.crossJoin(distinct_names.selectExpr('name1 as name2')).cache()\n",
    "distinct_name_pairs.show()\n",
    "print(distinct_name_pairs.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_name_pairs_w_metric = distinct_name_pairs.withColumn(\n",
    "  \"name1_name2_levenshtein\",\n",
    "  F.levenshtein(col(\"name1\"), col(\"name2\"))\n",
    ")\n",
    "\n",
    "distinct_name_pairs_w_metric = distinct_name_pairs_w_metric.withColumn(\n",
    "  \"name1_soundex\",\n",
    "  soundex(col(\"name1\"))\n",
    ").withColumn(\n",
    "  \"name2_soundex\",\n",
    "  soundex(col(\"name2\"))\n",
    ").cache()\n",
    "\n",
    "distinct_name_pairs_w_metric = distinct_name_pairs_w_metric.withColumn(\n",
    "  \"name1_name2_soundex_equality\",\n",
    "  soundex(col(\"name1\")) == soundex(col(\"name2\"))\n",
    ").withColumn(\n",
    "  \"name1_name2_levenshtein_equality\",\n",
    "  F.abs(distinct_name_pairs_w_metric.name1_name2_levenshtein) < 2\n",
    ")\n",
    "\n",
    "distinct_name_pairs_w_metric = distinct_name_pairs_w_metric.drop(\n",
    "    'name1_soundx'\n",
    ")\n",
    "\n",
    "distinct_name_pairs_w_metric = distinct_name_pairs_w_metric.select('name1','name2','name1_name2_soundex_equality','name1_name2_levenshtein_equality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+----------------------------+\n",
      "|              name1|              name2|name1_name2_soundex_equality|\n",
      "+-------------------+-------------------+----------------------------+\n",
      "|          Recreatin|          Recreatin|                        true|\n",
      "|          Recreatin|         recreation|                        true|\n",
      "| Mechanical Physics| Mechanical Physics|                        true|\n",
      "| Mechanical Physics|Mechanical Physical|                        true|\n",
      "|         recreation|          Recreatin|                        true|\n",
      "|         recreation|         recreation|                        true|\n",
      "|Mechanical Physical| Mechanical Physics|                        true|\n",
      "|Mechanical Physical|Mechanical Physical|                        true|\n",
      "|  Theater and Drama|  Theater and Drama|                        true|\n",
      "|  Theater and Drama|  Theater and drame|                        true|\n",
      "|  Theater and drame|  Theater and Drama|                        true|\n",
      "|  Theater and drame|  Theater and drame|                        true|\n",
      "|   Computer Science|   Computer Science|                        true|\n",
      "|   Computer Science|      Computer tech|                        true|\n",
      "|      Computer tech|   Computer Science|                        true|\n",
      "|      Computer tech|      Computer tech|                        true|\n",
      "+-------------------+-------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soundex_matches = distinct_name_pairs_w_metric.filter(distinct_name_pairs_w_metric['name1_name2_soundex_equality'] == True).select('name1','name2','name1_name2_soundex_equality').cache()\n",
    "soundex_matches.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+\n",
      "|              groups|      groupId|\n",
      "+--------------------+-------------+\n",
      "|[Computer Science...|   8589934592|\n",
      "|[Theater and Dram...| 223338299392|\n",
      "|[Mechanical Physi...| 369367187456|\n",
      "|[recreation, Recr...|1675037245440|\n",
      "+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "soundex_groups = soundex_matches.select(\"name1\", \"name2\").groupBy('name1').agg(F.collect_set('name2').alias('groups'))\n",
    "soundex_groups = soundex_groups.select('groups').drop_duplicates()\n",
    "soundex_groups = soundex_groups.withColumn(\"groupId\", F.monotonically_increasing_id())\n",
    "soundex_groups.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+\n",
      "|    id|               name|\n",
      "+------+-------------------+\n",
      "|123456|   Computer Science|\n",
      "|789012| Mechanical Physics|\n",
      "|345678|  Theater and Drama|\n",
      "|901234|         recreation|\n",
      "|123457|      Computer tech|\n",
      "|789013|Mechanical Physical|\n",
      "|345679|  Theater and drame|\n",
      "|901235|          Recreatin|\n",
      "+------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------------------+--------------------+-------------+\n",
      "|    id|               name|              groups|      groupId|\n",
      "+------+-------------------+--------------------+-------------+\n",
      "|123456|   Computer Science|[Computer Science...|   8589934592|\n",
      "|789012| Mechanical Physics|[Mechanical Physi...| 369367187456|\n",
      "|345678|  Theater and Drama|[Theater and Dram...| 223338299392|\n",
      "|901234|         recreation|[recreation, Recr...|1675037245440|\n",
      "|123457|      Computer tech|[Computer Science...|   8589934592|\n",
      "|789013|Mechanical Physical|[Mechanical Physi...| 369367187456|\n",
      "|345679|  Theater and drame|[Theater and Dram...| 223338299392|\n",
      "|901235|          Recreatin|[recreation, Recr...|1675037245440|\n",
      "+------+-------------------+--------------------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cat_df.join(soundex_groups, F.expr(\"array_contains(groups, name)\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
