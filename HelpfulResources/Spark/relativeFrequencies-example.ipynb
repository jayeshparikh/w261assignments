{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relative Frequencies example\n",
    "## Relative Frequencies\n",
    "__Data Intensive Text Processing__   \n",
    "Lin and Dyer   \n",
    "3.3 COMPUTING RELATIVE FREQUENCIES   \n",
    "(ported to Spark RDD API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import ast\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session (RUN THIS CELL AS IS)\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"relative_frequencies\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 10 ms, total: 20 ms\n",
      "Wall time: 168 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "DATA_toy = sc.parallelize(['dog aardvark pig banana','bear zebra pig'])\n",
    "DATA_toy.glom().collect()\n",
    "# using glom, we can see that there were as many partitions created as there are cores on this machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A BILL FOR ESTABLISHING RELIGIOUS',\n",
       " 'A Biography of General George',\n",
       " 'A Case Study in Government',\n",
       " 'A Case Study of Female',\n",
       " 'A Case Study of Limited']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA_F1 = sc.textFile(\"/media/notebooks/Assignments/HW3/master/data/googlebooks-eng-all-5gram-20090715-0-filtered.txt\")\\\n",
    "            .map(lambda x: x.split('\\t')[0]).cache()\n",
    "DATA_F1.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A CATALOGUE OF THE PATHOLOGICAL',\n",
       " 'A CT scan shows a',\n",
       " 'A Case of Frustrated Take',\n",
       " 'A Catalogue of Books and',\n",
       " 'A Celebration of the First']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DATA = sc.textFile(\"/media/notebooks/Assignments/HW3/master/data\").map(lambda x: x.split('\\t')[0]).cache()\n",
    "DATA.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from operator import add\n",
    "from collections import defaultdict\n",
    "\n",
    "def makePairs(row):\n",
    "    words = row.split(' ')\n",
    "    for w1, w2 in combinations(words, 2):\n",
    "        yield((w1,\"*\"),1)\n",
    "        yield((w1,w2),1)\n",
    "        \n",
    "        \n",
    "def partitionByWord(x):\n",
    "    return hash(x[0][0])\n",
    "\n",
    "def partMapper(seq):\n",
    "    currPair, currWord, pairTotal, wordTotal = None, None, 0, 0\n",
    "    for r in list(seq):\n",
    "        w1, w2 = r[0][0], r[0][1]\n",
    "        if w2 == \"*\":\n",
    "            if w1 != currWord: \n",
    "                wordTotal = 0\n",
    "                currWord = w1\n",
    "            wordTotal += r[1]    \n",
    "        else:\n",
    "            pairTotal += r[1]\n",
    "        \n",
    "            if currPair != r[0]: \n",
    "                yield(w1+\" - \"+w2, pairTotal/wordTotal)\n",
    "                pairTotal = 0\n",
    "                currPair = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_v1_sm = DATA_toy.flatMap(makePairs)\\\n",
    "          .repartitionAndSortWithinPartitions(numPartitions=2, \n",
    "                                                  ascending=True, \n",
    "                                                  partitionFunc=partitionByWord,\n",
    "                                                  keyfunc=lambda x: (x[0],x[1]))\\\n",
    "          .mapPartitions(partMapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 110 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('bear - pig', 0.5),\n",
       "  ('bear - zebra', 0.5),\n",
       "  ('dog - aardvark', 0.3333333333333333),\n",
       "  ('dog - banana', 0.3333333333333333),\n",
       "  ('dog - pig', 0.3333333333333333),\n",
       "  ('pig - banana', 1.0)],\n",
       " [('aardvark - banana', 0.5), ('aardvark - pig', 0.5), ('zebra - pig', 1.0)]]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD_v1_sm.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_v1_med = DATA_F1.flatMap(makePairs)\\\n",
    "          .repartitionAndSortWithinPartitions(numPartitions=2, \n",
    "                                                  ascending=True, \n",
    "                                                  partitionFunc=partitionByWord,\n",
    "                                                  keyfunc=lambda x: (x[0],x[1]))\\\n",
    "          .mapPartitions(partMapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 10 ms, total: 20 ms\n",
      "Wall time: 11.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('C - a', 0.02),\n",
       " ('C - activation', 0.04),\n",
       " ('C - and', 0.02),\n",
       " ('C - by', 0.1),\n",
       " ('C - circumference', 0.02)]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD_v1_med.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RelFreq_repartition.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "from operator import add\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def makePairsWithinPartition(seq):\n",
    "    pairsDict = defaultdict(int)\n",
    "    for row in seq:\n",
    "        words = row.split(' ')\n",
    "        for w1, w2 in combinations(words, 2):\n",
    "            pairsDict[(w1,\"*\")]+=1\n",
    "            pairsDict[(w1,w2)] += 1       \n",
    "    for k,v in pairsDict.items():\n",
    "        yield(k,v)\n",
    "    \n",
    "def partitionByWord(x):\n",
    "    return hash(x[0][0])\n",
    "\n",
    "\n",
    "def calcRelFreq(seq):    \n",
    "    \n",
    "    seq = sorted(seq, key=lambda tup: (tup[0][0], tup[0][1]))\n",
    "    \n",
    "    currPair, currWord, pairTotal, wordTotal = None, None, 0, 0\n",
    "    for r in list(seq):\n",
    "        w1, w2 = r[0][0], r[0][1]\n",
    "        if w2 == \"*\":\n",
    "            if w1 != currWord: \n",
    "                wordTotal = 0\n",
    "                currWord = w1\n",
    "            wordTotal += r[1]    \n",
    "        else:\n",
    "            pairTotal += r[1]\n",
    "        \n",
    "            if currPair != r[0]: \n",
    "                yield(w1+\" - \"+w2, pairTotal/wordTotal)\n",
    "                pairTotal = 0\n",
    "                currPair = r[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_sm = DATA_toy.mapPartitions(makePairsWithinPartition)\\\n",
    "              .reduceByKey(add, numPartitions=2, partitionFunc=partitionByWord)\\\n",
    "              .mapPartitions(calcRelFreq, True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 ms, sys: 0 ns, total: 20 ms\n",
      "Wall time: 169 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[('bear - pig', 0.5),\n",
       "  ('bear - zebra', 0.5),\n",
       "  ('dog - aardvark', 0.3333333333333333),\n",
       "  ('dog - banana', 0.3333333333333333),\n",
       "  ('dog - pig', 0.3333333333333333),\n",
       "  ('pig - banana', 1.0)],\n",
       " [('aardvark - banana', 0.5), ('aardvark - pig', 0.5), ('zebra - pig', 1.0)]]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD_sm.glom().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_med = DATA_F1.mapPartitions(makePairsWithinPartition)\\\n",
    "              .reduceByKey(add,numPartitions=2, partitionFunc=partitionByWord)\\\n",
    "              .mapPartitions(calcRelFreq, True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10 ms, sys: 0 ns, total: 10 ms\n",
      "Wall time: 5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('C - a', 0.04),\n",
       " ('C - activation', 0.02),\n",
       " ('C - and', 0.1),\n",
       " ('C - by', 0.02),\n",
       " ('C - circumference', 0.02)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD_med.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"RelFreq_reduceByKey.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDD_lg = DATA.flatMap(makePairs)\\\n",
    "          .reduceByKey(add,partitionFunc=partitionByWord)\\\n",
    "          .mapPartitions(calcRelFreq, True)\\\n",
    "          .cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 100 ms, sys: 50 ms, total: 150 ms\n",
      "Wall time: 10min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('o - A', 0.0006691201070592171),\n",
       " ('o - ARNO', 0.00033456005352960856),\n",
       " ('o - Adrianne', 0.00033456005352960856),\n",
       " ('o - Affairs', 0.00033456005352960856),\n",
       " ('o - America', 0.00033456005352960856)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "RDD_lg.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version 3\n",
    "Can we get the best of both worlds? Using the framework to combine as well as do secondary sort for us?   \n",
    "TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composite keys!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: calculate averages example with aggragateByKey\n",
    "aTuple = (0,0) # As of Python3, you can't pass a literal sequence to a function.\n",
    "rdd1 = rdd1.aggregateByKey(aTuple, lambda a,b: (a[0] + b,    a[1] + 1),\n",
    "                                       lambda a,b: (a[0] + b[0], a[1] + b[1]))\n",
    "finalResult = rdd1.mapValues(lambda v: v[0]/v[1]).collect()\n",
    "\n",
    "'''\n",
    "First lambda expression for Within-Partition Reduction Step::\n",
    "a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "b: is a SCALAR that holds the next Value\n",
    "\n",
    "Second lambda expression for Cross-Partition Reduction Step::\n",
    "a: is a TUPLE that holds: (runningSum, runningCount).\n",
    "b: is a TUPLE that holds: (nextPartitionsSum, nextPartitionsCount).\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
