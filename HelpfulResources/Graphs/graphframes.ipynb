{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphFrames example\n",
    "Last updated November 7, 2019\n",
    "\n",
    "w261 - Machine learning at Scale   \n",
    "Kyle Hamilton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark packages\n",
    "https://spark-packages.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--packages graphframes:graphframes:0.7.0-spark2.3-s_2.11 pyspark-shell\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "PACKAGES = ['graphframes:graphframes:0.7.0-spark2.3-s_2.11']\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = f\"--packages {','.join(PACKAGES)} pyspark-shell\"\n",
    "print(os.environ['PYSPARK_SUBMIT_ARGS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "app_name = \"graphframe_demo\"\n",
    "master = \"local[*]\"\n",
    "spark = SparkSession\\\n",
    "        .builder\\\n",
    "        .appName(app_name)\\\n",
    "        .master(master)\\\n",
    "        .getOrCreate()\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://docker.w261:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.3.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>graphframe_demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fac86bc7d68>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Vertex DataFrame with unique ID column \"id\"\n",
    "v = spark.createDataFrame([\n",
    "  (\"a\", \"Alice\", 34),\n",
    "  (\"b\", \"Bob\", 36),\n",
    "  (\"c\", \"Charlie\", 30),\n",
    "], [\"id\", \"name\", \"age\"])\n",
    "# Create an Edge DataFrame with \"src\" and \"dst\" columns\n",
    "e = spark.createDataFrame([\n",
    "  (\"a\", \"b\", \"friend\"),\n",
    "  (\"b\", \"c\", \"follow\"),\n",
    "  (\"c\", \"b\", \"follow\"),\n",
    "], [\"src\", \"dst\", \"relationship\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+---+\n",
      "| id|   name|age|\n",
      "+---+-------+---+\n",
      "|  a|  Alice| 34|\n",
      "|  b|    Bob| 36|\n",
      "|  c|Charlie| 30|\n",
      "+---+-------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+------------+\n",
      "|src|dst|relationship|\n",
      "+---+---+------------+\n",
      "|  a|  b|      friend|\n",
      "|  b|  c|      follow|\n",
      "|  c|  b|      follow|\n",
      "+---+---+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  c|       1|\n",
      "|  b|       2|\n",
      "+---+--------+\n",
      "\n",
      "+---+------------------+\n",
      "| id|          pagerank|\n",
      "+---+------------------+\n",
      "|  b|1.0905890109440908|\n",
      "|  a|              0.01|\n",
      "|  c|1.8994109890559092|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a GraphFrame\n",
    "from graphframes import *\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "# Query: Get in-degree of each vertex.\n",
    "g.inDegrees.show()\n",
    "\n",
    "# Query: Count the number of \"follow\" connections in the graph.\n",
    "g.edges.filter(\"relationship = 'follow'\").count()\n",
    "\n",
    "# Run PageRank algorithm, and show results.\n",
    "results = g.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.select(\"id\", \"pagerank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\t{'3': 1}\n",
      "3\t{'2': 1}\n",
      "4\t{'1': 1, '2': 1}\n",
      "5\t{'4': 1, '2': 1, '6': 1}\n",
      "6\t{'2': 1, '5': 1}\n",
      "7\t{'2': 1, '5': 1}\n",
      "8\t{'2': 1, '5': 1}\n",
      "9\t{'2': 1, '5': 1}\n",
      "10\t{'5': 1}\n",
      "11\t{'5': 1}"
     ]
    }
   ],
   "source": [
    "!cat test_graph.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphData = spark.read.format(\"com.databricks.spark.csv\") \\\n",
    "    .option(\"delimiter\", \"\\t\") \\\n",
    "    .option(\"header\", \"false\") \\\n",
    "    .load('test_graph.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(_c0='2', _c1=\"{'3': 1}\")]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphData.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = graphData.select('_c0').withColumnRenamed('_c0','id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  2|\n",
      "|  3|\n",
      "|  4|\n",
      "|  5|\n",
      "|  6|\n",
      "|  7|\n",
      "|  8|\n",
      "|  9|\n",
      "| 10|\n",
      "| 11|\n",
      "+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "v.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast\n",
    "def getEdges(row):\n",
    "    node_id, nodes = row\n",
    "    nodes = ast.literal_eval(nodes)\n",
    "    for node in nodes: \n",
    "        yield int(node_id), int(node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = spark.createDataFrame(graphData.rdd.flatMap(getEdges), [\"src\", \"dst\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|src|dst|\n",
      "+---+---+\n",
      "|  2|  3|\n",
      "|  3|  2|\n",
      "|  4|  1|\n",
      "|  4|  2|\n",
      "|  5|  4|\n",
      "|  5|  2|\n",
      "|  5|  6|\n",
      "|  6|  2|\n",
      "|  6|  5|\n",
      "|  7|  2|\n",
      "|  7|  5|\n",
      "|  8|  2|\n",
      "|  8|  5|\n",
      "|  9|  2|\n",
      "|  9|  5|\n",
      "| 10|  5|\n",
      "| 11|  5|\n",
      "+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "e.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "| id|inDegree|\n",
      "+---+--------+\n",
      "|  6|       1|\n",
      "|  5|       6|\n",
      "|  1|       1|\n",
      "|  3|       1|\n",
      "|  2|       7|\n",
      "|  4|       1|\n",
      "+---+--------+\n",
      "\n",
      "+---+--------------------+\n",
      "| id|            pagerank|\n",
      "+---+--------------------+\n",
      "|  8|0.010000000000000014|\n",
      "|  4| 0.02956384319612453|\n",
      "|  6| 0.02956384319612453|\n",
      "| 11|0.010000000000000014|\n",
      "| 10|0.010000000000000014|\n",
      "|  5|0.059284062207826185|\n",
      "|  3|   6.360951017965119|\n",
      "|  9|0.010000000000000014|\n",
      "|  7|0.010000000000000014|\n",
      "|  2|  3.4706372334348052|\n",
      "+---+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a GraphFrame\n",
    "from graphframes import *\n",
    "g = GraphFrame(v, e)\n",
    "\n",
    "# Query: Get in-degree of each vertex.\n",
    "g.inDegrees.show()\n",
    "\n",
    "# Run PageRank algorithm, and show results.\n",
    "results = g.pageRank(resetProbability=0.01, maxIter=20)\n",
    "results.vertices.select(\"id\", \"pagerank\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql import Row\n",
    "# from pyspark.sql import types\n",
    "# import pyspark.sql.functions as F\n",
    "# # Not what we want\n",
    "# graphData.select(F.explode(graphData._c1).alias(\"key\", \"value\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
