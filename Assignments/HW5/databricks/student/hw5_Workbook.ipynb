{"cells":[{"cell_type":"markdown","source":["# HW 5 - Page Rank\n__`MIDS w261: Machine Learning at Scale | UC Berkeley School of Information | Fall 2018`__\n\nIn Weeks 8 and 9 you discussed key concepts related to graph based algorithms and implemented SSSP.   \nIn this final homework assignment you'll implement distributed PageRank using some data from Wikipedia.\nBy the end of this homework you should be able to:  \n* ... __compare/contrast__ adjacency matrices and lists as representations of graphs for parallel computation.\n* ... __explain__ the goal of the PageRank algorithm using the concept of an infinite Random Walk.\n* ... __define__ a Markov chain including the conditions underwhich it will converge.\n* ... __identify__ what modifications must be made to the web graph inorder to leverage Markov Chains.\n* ... __implement__ distributed PageRank in Spark.\n\n__Please refer to the `README` for homework submission instructions and additional resources.__"],"metadata":{}},{"cell_type":"markdown","source":["# Notebook Set-Up\nBefore starting your homework run the following cells to confirm your setup."],"metadata":{}},{"cell_type":"code","source":["# imports\nimport re\nimport ast\nimport time\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport networkx as nx\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":3},{"cell_type":"markdown","source":["### Run the next cell to create your directory in dbfs\nYou do not need to understand this scala snippet. It simply dynamically fetches your user directory name so that any files you write can be saved in your own directory."],"metadata":{}},{"cell_type":"code","source":["# RUN THIS CELL AS IS\n# This code snippet reads the user directory name, and stores is in a python variable.\n# Next, it creates a folder inside your home folder, which you will use for files which you save inside this notebook.\nusername = dbutils.notebook.entry_point.getDbutils().notebook().getContext().tags().apply('user')\nuserhome = 'dbfs:/user/' + username\nprint(userhome)\nhw5_path = userhome + \"/HW5/\" \nhw5_path_open = '/dbfs' + hw5_path.split(':')[-1] # for use with python open()\ndbutils.fs.mkdirs(hw5_path)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">dbfs:/user/jayesh_parikh@ischool.berkeley.edu\nOut[3]: True</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# RUN THIS CELL AS IS. \nsum = 0\nDATA_PATH = 'dbfs:/mnt/mids-w261/data/HW5/'\nfor item in dbutils.fs.ls(DATA_PATH):\n  sum = sum+item.size\nsum"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[4]: 4751198766</div>"]}}],"execution_count":6},{"cell_type":"code","source":["# RUN THIS CELL AS IS. You should see all-pages-indexed-in.txt, all-pages-indexed-out.txt and indices.txt in the results. If you do not see these, please let an Instructor or TA know.\ndisplay(dbutils.fs.ls(DATA_PATH))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/mnt/mids-w261/data/HW5/all-pages-indexed-in.txt</td><td>all-pages-indexed-in.txt</td><td>2143300687</td></tr><tr><td>dbfs:/mnt/mids-w261/data/HW5/all-pages-indexed-out.txt</td><td>all-pages-indexed-out.txt</td><td>2090459616</td></tr><tr><td>dbfs:/mnt/mids-w261/data/HW5/indices.txt</td><td>indices.txt</td><td>517438296</td></tr><tr><td>dbfs:/mnt/mids-w261/data/HW5/test_graph.txt</td><td>test_graph.txt</td><td>167</td></tr></tbody></table></div>"]}}],"execution_count":7},{"cell_type":"code","source":["# RUN THIS CELL AS IS - A test to make sure your directory is working as expected.\n# You should see a result like:\n# dbfs:/user/youremail@ischool.berkeley.edu/HW5/test.txt\ndbutils.fs.put(hw5_path+'test.txt',\"hello world\",True)\ndisplay(dbutils.fs.ls(hw5_path))\n"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/user/jayesh_parikh@ischool.berkeley.edu/HW5/test.txt</td><td>test.txt</td><td>11</td></tr></tbody></table></div>"]}}],"execution_count":8},{"cell_type":"code","source":["sc = spark.sparkContext\nspark"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://10.74.243.165:48469\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v2.4.5</code></dd>\n              <dt>Master</dt>\n                <dd><code>spark://10.74.243.165:7077</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Databricks Shell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "]}}],"execution_count":9},{"cell_type":"markdown","source":["# Question 1: Distributed Graph Processing\nChapter 5 from Lin & Dyer gave you a high level introduction to graph algorithms and concernts that come up when trying to perform distributed computations over them. The questions below are designed to make sure you captured the key points from this reading and your async lectures. \n\n### Q1 Tasks:\n\n* __a) short response:__ Give an example of a dataset that would be appropriate to represent as a graph. What are the nodes/edges in this dataset? Is the graph you describe 'directed' or 'undirected'? What would the average \"in-degree\" of a node mean in the context of your example? \n\n* __b) short response:__ Other than their size/scale, what makes graphs uniquely challenging to work with in the map-reduce paradigm? *(__HINT__: Do not respond in terms of any specific algorithm. Think in terms of the nature of the graph datastructure itself).*\n\n* __c) short response:__ Briefly describe Dijskra's algorithm (goal/approach). What specific design component makes this approach hard to parallelize?\n\n* __d) short response:__ How does parallel breadth-first-search get around the problem that you identified in part `c`? At what expense?"],"metadata":{}},{"cell_type":"markdown","source":["### Q1 Student Answers:\n> __a)__ Social Networking site is an example of dataset what can be represented as a graph. Friends and Family members would represent as nodes and relationships would represent as edges. This graph would be described as 'undirected'. The degree of a node is simply the summation of all the edges linked to it. The average degree is summation of all nodes’ degree divided by the total number of nodes. \n\n> __b)__ It is not possible to communicate global state from node to node within map-reduce framework as well as maintain the global data structures in memory\n\n> __c)__ Dijskra's algorithm maintains a global priority queue of nodes with priorities equal to their distance from the source node. At each iteration, the algorithm expands the node with the shortest distance & updates distance to all reachable nodes. The key to Dijskra's algorithm is that it maintains a global priority queue which makes it hard to parallelize.\n\n> __d)__ Parallel breadth-first-search is an iterative algorithm where each iteration corresponds to a map-reduce job. The algorithm works by mapping over all the nodes and emitting a key-value pair for each neighbor on  the node's adjacency list. Parallel breadth-first-search requires multiple iterations to traverse through all the nodes"],"metadata":{}},{"cell_type":"markdown","source":["# Question 2: Representing Graphs \n\nIn class you saw examples of adjacency matrix and adjacency list representations of graphs. These data structures were probably familiar from HW3, though we hadn't before talked about them in the context of graphs. In this question we'll discuss some of the tradeoffs associated with these representations. __`NOTE:`__ We'll use the graph from Figure 5.1 in Lin & Dyer as a toy example. For convenience in the code below we'll label the nodes `A`, `B`, `C`, `D`, and `E` instead of $n_1$, $n_2$, etc but otherwise you should be able to follow along & check our answers against those in the text.\n\n<img src=\"https://github.com/kyleiwaniec/w261_assets/blob/master/images/HW5/Lin-Dyer-graph-Q1.png?raw=true\" width=50%>\n\n### Q2 Tasks:\n\n* __a) short response:__ Relatively speaking, is the graph you described in Figure 5.1 in Lin & Dyer \"sparse\" or \"dense\"?  Explain how sparsity/density impacts the adjacency matrix and adjacency list representations of a graph.\n\n* __b) short response:__ Run the provided code to create and plot our toy graph. Is this graph directed or undirected? Explain how the adjacency matrices for directed graphs will differ from those of undirected graphs.\n\n* __c) code:__ Fill in the missing code to complete the function `get_adj_matr()`.\n\n* __d) code:__ Fill in the missing code to complete the function `get_adj_list()`."],"metadata":{}},{"cell_type":"markdown","source":["### Q2 Student Answers:\n> __a)__ The graph described in Figure 5.1 in Lin & Dyer is a sparse graph. The major problem with an adjacency matrix representation of sparse graphs is it's \\\\( O(n^2) \\\\) space requirements.\n\n> __b)__ This graph is directed as it shows directed edges from the nodes.  If the graph is undirected, the adjacency matrix is symmetric whereas for a directed graph, the adjacency matrix does not need to be symmetric."],"metadata":{}},{"cell_type":"code","source":["# part a - a graph is just a list of nodes and edges (RUN THIS CELL AS IS)\nTOY_GRAPH = {'nodes':['A', 'B', 'C', 'D', 'E'],\n             'edges':[('A', 'B'), ('A', 'D'), ('B', 'C'), ('B', 'E'), ('C', 'D'), \n                      ('D', 'E'), ('E', 'A'),('E', 'B'), ('E', 'C')]}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":14},{"cell_type":"code","source":["# part a - simple visualization of our toy graph using nx (RUN THIS CELL AS IS)\nG = nx.DiGraph()\nG.add_nodes_from(TOY_GRAPH['nodes'])\nG.add_edges_from(TOY_GRAPH['edges'])\ndisplay(nx.draw(G, pos=nx.circular_layout(G), with_labels=True, alpha = 0.5))"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["# part c - adjacency matrix function\ndef get_adj_matr(graph):\n    \"\"\"\n    Function to create an adjacency matrix representation of a graph.\n    arg:\n        graph - (dict) of 'nodes' : [], 'edges' : []\n    returns:\n        pd.DataFrame with entry i,j representing an edge from node i to node j\n    \"\"\"\n    n = len(graph['nodes'])\n    adj_matr = pd.DataFrame(0, columns = graph['nodes'], index = graph['nodes'])\n    ############### YOUR CODE HERE ##################\n    for edge in graph['edges']:\n        adj_matr.set_value(edge[0], edge[1], 1)\n        \n    #print(len(graph['edges']))\n    ############### (END) YOUR CODE #################\n    return adj_matr"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":16},{"cell_type":"code","source":["# part c - take a look (RUN THIS CELL AS IS)\nTOY_ADJ_MATR = get_adj_matr(TOY_GRAPH)\nprint(TOY_ADJ_MATR)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1584319937006-0/PythonShell.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n  import time\n   A  B  C  D  E\nA  0  1  0  1  0\nB  0  0  1  0  1\nC  0  0  0  1  0\nD  0  0  0  0  1\nE  1  1  1  0  0\n</div>"]}}],"execution_count":17},{"cell_type":"code","source":["# part d - adjacency list function\ndef get_adj_list(graph):\n    \"\"\"\n    Function to create an adjacency list representation of a graph.\n    arg:\n        graph - (dict) of 'nodes' : [], 'edges' : []\n    returns:\n        dictionary of the form {node : [list of edges]}\n    \"\"\"\n    adj_list = {node: [] for node in graph['nodes']}\n    ############### YOUR CODE HERE ##################\n    for node in graph['nodes']:\n       for edge in graph['edges']:\n          if edge[0] == node:\n            adj_list[node].append(edge[1])\n    \n    ############### (END) YOUR CODE #################\n    return adj_list"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":18},{"cell_type":"code","source":["# part d - take a look (RUN THIS CELL AS IS)\nTOY_ADJ_LIST = get_adj_list(TOY_GRAPH)\nprint(TOY_ADJ_LIST)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">{&#39;A&#39;: [&#39;B&#39;, &#39;D&#39;], &#39;B&#39;: [&#39;C&#39;, &#39;E&#39;], &#39;C&#39;: [&#39;D&#39;], &#39;D&#39;: [&#39;E&#39;], &#39;E&#39;: [&#39;A&#39;, &#39;B&#39;, &#39;C&#39;]}\n</div>"]}}],"execution_count":19},{"cell_type":"markdown","source":["# Question 3: Markov Chains and Random Walks\n\nAs you know from your readings and in class discussions, the PageRank algorithm takes advantage of the machinery of Markov Chains to compute the relative importance of a webpage using the hyperlink structure of the web (we'll refer to this as the 'web-graph'). A Markov Chain is a discrete-time stochastic process. The stochastic matrix has a principal left eigen vector corresponding to its largest eigen value which is one. A Markov chain's probability distribution over its states may be viewed as a probability vector. This steady state probability for a state is the PageRank of the corresponding webpage. In this question we'll briefly discuss a few concepts that are key to understanding the math behind PageRank. \n\n### Q3 Tasks:\n\n* __a) short response:__ It is common to explain PageRank using the analogy of a web surfer who clicks on links at random ad infinitum. In the context of this hypothetical infinite random walk, what does the PageRank metric measure/represent?\n\n* __b) short response:__ What is the \"Markov Property\" and what does it mean in the context of PageRank?\n\n* __c) short response:__ A Markov chain consists of $n$ states plus an $n\\times n$ transition probability matrix. In the context of PageRank & a random walk over the WebGraph what are the $n$ states? what implications does this have about the size of the transition matrix?\n\n* __d) code + short response:__ What is a \"right stochastic matrix\"? Fill in the code below to compute the transition matrix for the toy graph from question 2. [__`HINT:`__ _It should be right stochastic. Using numpy this calculation can be done in one line of code._]\n\n* __e) code + short response:__ To compute the stable state distribution (i.e. PageRank) of a \"nice\" graph we can apply the power iteration method - repeatedly multiplying the transition matrix by itself, until the values no longer change. Apply this strategy to your transition matrix from `part d` to find the PageRank for each of the pages in your toy graph. Your code should print the results of each iteration. How many iterations does it take to converge? Which node is most 'central' (i.e. highest ranked)? Does this match your intuition? \n    * __`NOTE 1:`__ _this is a naive approach, we'll unpack what it means to be \"nice\" in the next question_.\n    * __`NOTE 2:`__ _no need to implement a stopping criteria, visual inspection should suffice_."],"metadata":{}},{"cell_type":"markdown","source":["### Q3 Student Answers:\n> __a)__ PageRank is used to give each page a relative score of importance and authority by evaluating the quality and quantity of its links.\n\n> __b)__ Markov Property in mathematical term state that the conditional distribution of future states of the process given present and past states depends only on the present state and not at all on the past states (memoryless property). PageRank models the network of Web pages by a Markov chain. This network is a huge ﬁnite state machine, where every state is a page and that the page ranks are proportional to the stationary probabilities of the states in the Markov chain. \n\n> __c)__ \\\\( n \\\\) states are the pages (websites).  \\\\( n \\times n \\\\) represents a transition matrix -> a Markov process whose steady state distribution tells about which  pages we spend a lot of time on. This distribution speciﬁes what proportion of time on average is spent at speciﬁc node during an inﬁnitely long random walk. One issue with this approach is the fact that chain can ‘get stuck’ at the nodes that have no outgoing links, and the nodes with no incoming links are never visited in the random walk. \n\n> __d)__ A right stochastic matrix is a real square matrix, with each row summing to 1.\n\n> __e)__ 3 iteration to converge...node E is the highest ranked which matches what is observed on the graph"],"metadata":{}},{"cell_type":"code","source":["# part d - recall what the adjacency matrix looked like (RUN THIS CELL AS IS)\nTOY_ADJ_MATR"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>A</th>\n      <th>B</th>\n      <th>C</th>\n      <th>D</th>\n      <th>E</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>A</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>B</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>C</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>D</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>E</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"]}}],"execution_count":22},{"cell_type":"code","source":["# part d - use TOY_ADJ_MATR to create a right stochastic transition matrix for this graph\n################ YOUR CODE HERE #################\ntransition_matrix = TOY_ADJ_MATR / TOY_ADJ_MATR.sum(axis=1)[:,None] # replace with your code\n\n################ (END) YOUR CODE #################\nprint(transition_matrix)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">          A         B         C    D    E\nA  0.000000  0.500000  0.000000  0.5  0.0\nB  0.000000  0.000000  0.500000  0.0  0.5\nC  0.000000  0.000000  0.000000  1.0  0.0\nD  0.000000  0.000000  0.000000  0.0  1.0\nE  0.333333  0.333333  0.333333  0.0  0.0\n</div>"]}}],"execution_count":23},{"cell_type":"code","source":["# part e - compute the steady state using the transition matrix \ndef power_iteration(xInit, tMatrix, nIter, verbose = True):\n    \"\"\"\n    Function to perform the specified number of power iteration steps to \n    compute the steady state probability distribution for the given\n    transition matrix.\n    \n    Args:\n        xInit     - (n x 1 array) representing inial state\n        tMatrix  - (n x n array) transition probabilities\n        nIter     - (int) number of iterations\n    Returns:\n        state_vector - (n x 1 array) representing probability \n                        distribution over states after nSteps.\n    \n    NOTE: if the 'verbose' flag is on, your function should print the step\n    number and the current matrix at each iteration.\n    \"\"\"\n    #state_vector = xInit\n    state_vector = xInit.dot(tMatrix)\n    \n    ################ YOUR CODE HERE #################\n    for ix in range(nIter):    \n        \n        tMatrix = tMatrix.dot(tMatrix)\n        state_vector = state_vector.dot(tMatrix)\n        #state_vector = state_vector @ tMatrix\n        #state_vector = new_state_vector\n        \n        if verbose:\n            print(f'Step {ix}: {state_vector}')\n      \n    ################ (END) YOUR CODE #################\n    return state_vector"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":24},{"cell_type":"code","source":["# part e - run 10 steps of the power_iteration (RUN THIS CELL AS IS)\nxInit = np.array([1.0, 0, 0, 0, 0]) # note that this initial state will not affect the convergence states\n#xInit = np.ones(transition_matrix.shape[1]) / (transition_matrix.shape[1])\nstates = power_iteration(xInit, transition_matrix, 10, verbose = True)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Step 0: [0.25 0.25 0.25 0.25 0.  ]\nStep 1: [0.0625     0.13541667 0.16666667 0.28125    0.35416667]\nStep 2: [0.10575408 0.15948511 0.18465873 0.23851032 0.31159176]\nStep 3: [0.10526138 0.15789075 0.18420926 0.23683893 0.31579969]\nStep 4: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\nStep 5: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\nStep 6: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\nStep 7: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\nStep 8: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\nStep 9: [0.10526316 0.15789474 0.18421053 0.23684211 0.31578947]\n</div>"]}}],"execution_count":25},{"cell_type":"markdown","source":["__`Expected Output for part e:`__  \n>Steady State Probabilities:\n```\nNode A: 0.10526316  \nNode B: 0.15789474  \nNode C: 0.18421053  \nNode D: 0.23684211  \nNode E: 0.31578947  \n```"],"metadata":{}},{"cell_type":"markdown","source":["# Question 4: Page Rank Theory\n\nSeems easy right? Unfortunately applying this power iteration method directly to the web-graph actually runs into a few problems. In this question we'll tease apart what we meant by a 'nice graph' in Question 3 and highlight key modifications we'll have to make to the web-graph when performing PageRank. To start, we'll look at what goes wrong when we try to repeat our strategy from question 3 on a 'not nice' graph.\n\n__`Additional References:`__ http://pi.math.cornell.edu/~mec/Winter2009/RalucaRemus/Lecture3/lecture3.html\n\n### Q4 Tasks:\n\n* __a) code + short response:__ Run the provided code to create and plot our 'not nice' graph. Fill in the missing code to compute its transition matrix & run the power iteration method from question 3. What is wrong with what you see? [__`HINT:`__ _there is a visible underlying reason that it isn't converging... try adding up the probabilities in the state vector after each iteration._]\n\n* __b) short response:__  Identify the dangling node in this 'not nice' graph and explain how this node causes the problem you described in 'a'. How could we modify the transition matrix after each iteration to prevent this problem?\n\n* __c) short response:__ What does it mean for a graph to be irreducible? Is the webgraph naturally irreducible? Explain your reasoning briefly.\n\n* __d) short response:__ What does it mean for a graph to be aperiodic? Is the webgraph naturally aperiodic? Explain your reasoning briefly.\n\n* __e) short response:__ What modification to the webgraph does PageRank make in order to guarantee aperiodicity and irreducibility? Interpret this modification in terms of our random surfer analogy."],"metadata":{}},{"cell_type":"markdown","source":["### Q4 Student Answers:\n> __a)__ Node E does not have outgoing edges so the probabililities are undefined\n\n> __b)__ Node E is the dangling node which is causing probabilities to be undefined. \n\n> __c)__ Irreducible: There is a path from every node to every other node. No, a webgraph may not be naturally irreducible as most of the times surfer would be jumping around different URLs and not necessarily follow a path from one node to another to create a 'nice' graph\n\n> __d)__ Aperiodic: The period, or greatest common divisor (GCD), of all cycle lengths is 1. A graph is aperiodic if the greatest common divisor of the lengths of its cycles is one; this greatest common divisor for a graph G is called the period of G. No, webgraph is not naturally aperiodic as length of its cycles can be greater than 1\n\n> __e)__ Webgraph modifications made to guarantee aperiodicity and irreducibility are 1) Stochasticity adjustment to resolves dangling edges and 2) Primitivity adjustment to incorporate teleportation. Both these modifications ensure that the Markov process underlying the webgraph will actually converge on a steady state distribution"],"metadata":{}},{"cell_type":"code","source":["# part a - run this code to create a second toy graph (RUN THIS CELL AS IS)\nTOY2_GRAPH = {'nodes':['A', 'B', 'C', 'D', 'E'],\n              'edges':[('A', 'B'), ('A', 'C'), ('A', 'D'), ('B', 'D'), \n                       ('B', 'E'), ('C', 'A'), ('C', 'E'), ('D', 'B')]}"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":29},{"cell_type":"code","source":["# part a - simple visualization of our test graph using nx (RUN THIS CELL AS IS)\nG = nx.DiGraph()\nG.add_nodes_from(TOY2_GRAPH['nodes'])\nG.add_edges_from(TOY2_GRAPH['edges'])\ndisplay(nx.draw(G, pos=nx.circular_layout(G), with_labels=True, alpha = 0.5))"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"code","source":["# part a - run 10 steps of the power iteration method here\n# HINT: feel free to use the functions get_adj_matr() and power_iteration() you wrote above\n################ YOUR CODE HERE #################\nTOY2_ADJ_MATR = get_adj_matr(TOY2_GRAPH)\nprint(TOY2_ADJ_MATR)\ntransition_matrix2 = TOY2_ADJ_MATR / TOY2_ADJ_MATR.sum(axis=1)[:,None]\nprint(transition_matrix2)\nxInit2 = np.array([1.0, 0, 0, 0, 0]) # note that this initial state will not affect the convergence states\nstates2 = power_iteration(xInit2, transition_matrix2, 10, verbose = True)\n\n################ (END) YOUR CODE #################"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">/local_disk0/tmp/1584319937006-0/PythonShell.py:14: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n  import time\n   A  B  C  D  E\nA  0  1  1  1  0\nB  0  0  0  1  1\nC  1  0  0  0  1\nD  0  1  0  0  0\nE  0  0  0  0  0\n     A         B         C         D    E\nA  0.0  0.333333  0.333333  0.333333  0.0\nB  0.0  0.000000  0.000000  0.500000  0.5\nC  0.5  0.000000  0.000000  0.000000  0.5\nD  0.0  1.000000  0.000000  0.000000  0.0\nE  NaN       NaN       NaN       NaN  NaN\nStep 0: [nan nan nan nan nan]\nStep 1: [nan nan nan nan nan]\nStep 2: [nan nan nan nan nan]\nStep 3: [nan nan nan nan nan]\nStep 4: [nan nan nan nan nan]\nStep 5: [nan nan nan nan nan]\nStep 6: [nan nan nan nan nan]\nStep 7: [nan nan nan nan nan]\nStep 8: [nan nan nan nan nan]\nStep 9: [nan nan nan nan nan]\n</div>"]}}],"execution_count":31},{"cell_type":"markdown","source":["# About the Data\nThe main dataset for this data consists of a subset of a 500GB dataset released by AWS in 2009. The data includes the source and metadata for all of the Wikimedia wikis. You can read more here: \n> https://aws.amazon.com/blogs/aws/new-public-data-set-wikipedia-xml-data. \n\nAs in previous homeworks we'll be using a 2GB subset of this data, which is available to you in this dropbox folder: \n> https://www.dropbox.com/sh/2c0k5adwz36lkcw/AAAAKsjQfF9uHfv-X9mCqr9wa?dl=0. \n\nUse the cells below to download the wikipedia data and a test file for use in developing your PageRank implementation(note that we'll use the 'indexed out' version of the graph) and to take a look at the files."],"metadata":{}},{"cell_type":"code","source":["dbutils.fs.ls(DATA_PATH)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[93]: [FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW5/all-pages-indexed-in.txt&#39;, name=&#39;all-pages-indexed-in.txt&#39;, size=2143300687),\n FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW5/all-pages-indexed-out.txt&#39;, name=&#39;all-pages-indexed-out.txt&#39;, size=2090459616),\n FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW5/indices.txt&#39;, name=&#39;indices.txt&#39;, size=517438296),\n FileInfo(path=&#39;dbfs:/mnt/mids-w261/data/HW5/test_graph.txt&#39;, name=&#39;test_graph.txt&#39;, size=167)]</div>"]}}],"execution_count":33},{"cell_type":"code","source":["# open test_graph.txt file to see format (RUN THIS CELL AS IS)\nwith open('/dbfs/mnt/mids-w261/data/HW5/test_graph.txt', \"r\") as f_read:\n  for line in f_read:\n    print(line)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">2\t{&#39;3&#39;: 1}\n\n3\t{&#39;2&#39;: 2}\n\n4\t{&#39;1&#39;: 1, &#39;2&#39;: 1}\n\n5\t{&#39;4&#39;: 3, &#39;2&#39;: 1, &#39;6&#39;: 1}\n\n6\t{&#39;2&#39;: 1, &#39;5&#39;: 2}\n\n7\t{&#39;2&#39;: 1, &#39;5&#39;: 1}\n\n8\t{&#39;2&#39;: 1, &#39;5&#39;: 1}\n\n9\t{&#39;2&#39;: 1, &#39;5&#39;: 1}\n\n10\t{&#39;5&#39;: 1}\n\n11\t{&#39;5&#39;: 2}\n</div>"]}}],"execution_count":34},{"cell_type":"code","source":["# load the data into Spark RDDs for convenience of use later (RUN THIS CELL AS IS)\ntestRDD = sc.textFile(DATA_PATH +'test_graph.txt')\nindexRDD = sc.textFile(DATA_PATH + '/indices.txt')\nwikiRDD = sc.textFile(DATA_PATH + '/all-pages-indexed-out.txt')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":35},{"cell_type":"code","source":["# display testRDD (RUN THIS CELL AS IS)\ntestRDD.take(20)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[109]: [&#34;2\\t{&#39;3&#39;: 1}&#34;,\n &#34;3\\t{&#39;2&#39;: 2}&#34;,\n &#34;4\\t{&#39;1&#39;: 1, &#39;2&#39;: 1}&#34;,\n &#34;5\\t{&#39;4&#39;: 3, &#39;2&#39;: 1, &#39;6&#39;: 1}&#34;,\n &#34;6\\t{&#39;2&#39;: 1, &#39;5&#39;: 2}&#34;,\n &#34;7\\t{&#39;2&#39;: 1, &#39;5&#39;: 1}&#34;,\n &#34;8\\t{&#39;2&#39;: 1, &#39;5&#39;: 1}&#34;,\n &#34;9\\t{&#39;2&#39;: 1, &#39;5&#39;: 1}&#34;,\n &#34;10\\t{&#39;5&#39;: 1}&#34;,\n &#34;11\\t{&#39;5&#39;: 2}&#34;]</div>"]}}],"execution_count":36},{"cell_type":"code","source":["# display indexRDD (RUN THIS CELL AS IS)\nindexRDD.take(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[97]: [&#39;! $var = &amp;quot;&amp;quot;\\t1\\t1\\t0&#39;,\n &#39;! (CONFIG.SYS directive)\\t2\\t1\\t1&#39;,\n &#39;! (album)\\t3\\t12\\t17&#39;,\n &#39;! (disambiguation)\\t4\\t1\\t20&#39;,\n &#39;! -attention-\\t5\\t1\\t0&#39;,\n &#39;! Time Zone\\t6\\t1\\t0&#39;,\n &#39;!! (chess)\\t7\\t0\\t1&#39;,\n &#39;!! (disambiguation)\\t8\\t3\\t0&#39;,\n &#39;!!! (Chk Chk Chk)\\t9\\t1\\t0&#39;,\n &#39;!!! (album)\\t10\\t5\\t15&#39;]</div>"]}}],"execution_count":37},{"cell_type":"code","source":["# display wikiRDD (RUN THIS CELL AS IS)\nwikiRDD.take(10)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[98]: [&#34;73\\t{&#39;14417532&#39;: 1}&#34;,\n &#34;299\\t{&#39;4214575&#39;: 1}&#34;,\n &#34;2552\\t{&#39;15043376&#39;: 1, &#39;13430968&#39;: 1, &#39;13451035&#39;: 1, &#39;7263397&#39;: 1, &#39;13001625&#39;: 1, &#39;13443575&#39;: 1, &#39;13451269&#39;: 1, &#39;13432316&#39;: 1, &#39;11623371&#39;: 1, &#39;15028971&#39;: 1, &#39;13425865&#39;: 1, &#39;15042703&#39;: 1, &#39;5051368&#39;: 1, &#39;9854998&#39;: 2, &#39;13442976&#39;: 1, &#39;13315025&#39;: 1, &#39;2992307&#39;: 1, &#39;1054486&#39;: 1, &#39;1322325&#39;: 1, &#39;13450983&#39;: 1}&#34;,\n &#34;2570\\t{&#39;983991&#39;: 1}&#34;,\n &#34;2616\\t{&#39;9045350&#39;: 1}&#34;,\n &#34;2711\\t{&#39;752887&#39;: 1}&#34;,\n &#34;2818\\t{&#39;3534183&#39;: 1}&#34;,\n &#34;2847\\t{&#39;3797918&#39;: 1}&#34;,\n &#34;2892\\t{&#39;2893&#39;: 1}&#34;,\n &#34;2921\\t{&#39;5158607&#39;: 1, &#39;6007184&#39;: 1, &#39;14773825&#39;: 1, &#39;11777840&#39;: 2, &#39;9285165&#39;: 1, &#39;6420484&#39;: 1, &#39;14670682&#39;: 1, &#39;7316613&#39;: 1, &#39;7125893&#39;: 1, &#39;14965920&#39;: 1, &#39;14229952&#39;: 1, &#39;9447742&#39;: 2, &#39;1425342&#39;: 1, &#39;11390944&#39;: 2, &#39;5141&#39;: 1, &#39;14928135&#39;: 2, &#39;13636570&#39;: 3, &#39;14687433&#39;: 1, &#39;15105458&#39;: 1, &#39;11656072&#39;: 1, &#39;6420027&#39;: 1, &#39;10898196&#39;: 1, &#39;6416278&#39;: 1, &#39;11497740&#39;: 2}&#34;]</div>"]}}],"execution_count":38},{"cell_type":"markdown","source":["# Question 5: EDA part 1 (number of nodes)\n\nAs usual, before we dive in to the main analysis, we'll peform some exploratory data anlysis to understand our dataset. Please use the test graph that you downloaded to test all your code before running the full dataset.\n\n### Q5 Tasks:\n* __a) short response:__ In what format is the raw data? What is the name of this data structure? What does the first value represent? What does the second part of each line represent? [__`HINT:`__ _no need to go digging here, just visually inspect the outputs of the head commands that we ran after loading the data above._]\n\n* __b) code + short response:__ Run the provided bash command to count the number of records in the raw dataset. Explain why this is _not_ the same as the number of total nodes in the graph.\n\n* __c) code:__ In the space provided below write a Spark job to count the _total number_ of nodes in this graph. \n\n* __d) short response:__ How many dangling nodes are there in this wikipedia graph? [__`HINT:`__ _you should not need any code to answer this question._]"],"metadata":{}},{"cell_type":"markdown","source":["### Q5 Student Answers:\n> __a)__ Raw data is in text format (tab delimited). Each line represents an adjacency list where first part is the key and second part as value\n\n> __b)__ This file represents webgraph (adjacency list) where each line represent node (key) and edges to other nodes (value).  Each record may include more than one node and nodes could be repeated on different row. So number of records is not same as number of nodes\n\n> __d)__ Dangling Nodes = 15192277 - 5781290 = 9410987"],"metadata":{}},{"cell_type":"code","source":["# part b - count the number of records in the raw data (RUN THIS CELL AS IS)\n# 5781290\nprint(wikiRDD.count())"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">5781290\n</div>"]}}],"execution_count":41},{"cell_type":"code","source":["# part c - write your Spark job here (compute total number of nodes)\ndef count_nodes(dataRDD):\n    \"\"\"\n    Spark job to count the total number of nodes.\n    Returns: integer count \n    \"\"\"    \n    ############## YOUR CODE HERE ###############\n    import ast\n\n    def getnodes(example):\n      edgenodes = ast.literal_eval(example)\n      for node in edgenodes:\n         yield int(node)\n    \n    # Keys are nodes connected to other nodes\n    nodes = dataRDD.map(lambda x: (int(x.split(\"\\t\")[0])))\n    \n    # get other nodes to which key (node) is connected with\n    values = dataRDD.map(lambda x: (x.split(\"\\t\")[1])).flatMap(getnodes).distinct()\n    \n    # Combine and get unique count of nodes\n    totalCount = nodes.union(values).distinct().count()\n           \n    ############## (END) YOUR CODE ###############   \n    return totalCount"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":42},{"cell_type":"code","source":["# part c - run your counting job on the test file (RUN THIS CELL AS IS)\nstart = time.time()\ntot = count_nodes(testRDD)\nprint(f'... completed job in {time.time() - start} seconds.')\nprint(f'Total Nodes: {tot}')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">... completed job in 0.47094082832336426 seconds.\nTotal Nodes: 11\n</div>"]}}],"execution_count":43},{"cell_type":"code","source":["# part c - run your counting job on the full file (RUN THIS CELL AS IS)\n# 5781290\nstart = time.time()\ntot = count_nodes(wikiRDD)\nprint(f'... completed job in {time.time() - start} seconds.')\nprint(f'Total Nodes: {tot}')"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">... completed job in 138.2423722743988 seconds.\nTotal Nodes: 15192277\n</div>"]}}],"execution_count":44},{"cell_type":"markdown","source":["# Question 6 - EDA part 2 (out-degree distribution)\n\nAs you've seen in previous homeworks the computational complexity of an implementation depends not only on the number of records in the original dataset but also on the number of records we create and shuffle in our intermediate representation of the data. The number of intermediate records required to update PageRank is related to the number of edges in the graph. In this question you'll compute the average number of hyperlinks on each page in this data and visualize a distribution for these counts (the out-degree of the nodes). \n\n### Q6 Tasks:\n* __a) code:__ In the space provided below write a Spark job to stream over the data and compute all of the following information:\n * count the out-degree of each non-dangling node and return the names of the top 10 pages with the most hyperlinks\n * find the average out-degree for all non-dangling nodes in the graph\n * take a 1000 point sample of these out-degree counts and plot a histogram of the result. \n \n \n* __b) short response:__ In the context of the PageRank algorithm, how is information about a node's out degree used?\n\n* __c) short response:__ What does it mean if a node's out-degree is 0? In PageRank how will we handle these nodes differently than others?\n \n__`NOTE:`__ Please observe scalability best practices in the design of your code & comment your work clearly. You will be graded on both the clarity and the design."],"metadata":{}},{"cell_type":"markdown","source":["### Q6 Student Answers:\n\n> __b)__ Information about node's out degree is used to determine dangling nodes and rank for the resp node.\n\n> __c)__ If a node's out-degree is 0, it is identified as a dangling node.  Dangling nodes result in loss of mass during initialization phase. The proper treatment of PageRank mass “lost\" at  the dangling nodes is to redistribute it across all  nodes in the graph evenly"],"metadata":{}},{"cell_type":"code","source":["# part a - write your Spark job here (compute average in-degree, etc)\ndef count_degree(dataRDD, n):\n    \"\"\"\n    Function to analyze out-degree of nodes in a a graph.\n    Returns: \n        top  - (list of 10 tuples) nodes with most edges\n        avgDegree - (float) average out-degree for non-dangling nodes\n        sampledCounts - (list of integers) out-degree for n randomly sampled non-dangling nodes\n    \"\"\"\n    # helper func\n    def parse(line):\n        node, edges = line.split('\\t')\n        return (node, ast.literal_eval(edges))\n    \n    ############## YOUR CODE HERE ###############\n    import ast\n    from statistics import mean\n    import random\n    \n    def getnodes(row):\n      node_id, nodes = row\n      nodes = ast.literal_eval(nodes)\n      for node in nodes:\n        yield node_id, node\n\n    nodes = dataRDD.map(lambda x: (x.split(\"\\t\")[0], x.split(\"\\t\")[1])).flatMap(getnodes).countByKey()\n    sorted_nodes = sorted(nodes.items(), key=lambda x: x[1], reverse=True)\n    top = sorted_nodes[:10]\n    \n    avgDegree = mean(nodes[k] for k in nodes)\n    \n    #randomly sample non dangling nodes\n    keys = random.sample(list(nodes), n)\n    \n    #get counts for those randomly selected nodes\n    sampledCounts = [nodes[k] for k in keys]\n    \n    #sampledCounts = dict(random.sample(nodes.items(), n))\n    \n    ############## (END) YOUR CODE ###############\n    \n    return top, avgDegree, sampledCounts"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":47},{"cell_type":"code","source":["# part a - run your job on the test file (RUN THIS CELL AS IS)\nstart = time.time()\ntest_results = count_degree(testRDD,10)\nprint(f\"... completed job in {time.time() - start} seconds\")\nprint(\"Average out-degree: \", test_results[1])\nprint(\"Top 10 nodes (by out-degree:)\\n\", test_results[0])\nprint(\"SampledCounts\", test_results[2])\nplt.hist(test_results[2], bins=10)\nplt.title(\"Distribution of Out-Degree\")\nplt.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">... completed job in 0.7314434051513672 seconds\nAverage out-degree:  1.7\nTop 10 nodes (by out-degree:)\n [(&#39;5&#39;, 3), (&#39;4&#39;, 2), (&#39;6&#39;, 2), (&#39;7&#39;, 2), (&#39;8&#39;, 2), (&#39;9&#39;, 2), (&#39;2&#39;, 1), (&#39;3&#39;, 1), (&#39;10&#39;, 1), (&#39;11&#39;, 1)]\nSampledCounts [1, 1, 1, 2, 2, 2, 2, 1, 3, 2]\n</div>"]}}],"execution_count":48},{"cell_type":"code","source":["# part a - run your job on the full file (RUN THIS CELL AS IS)\nstart = time.time()\nfull_results = count_degree(wikiRDD,1000)\nprint(f\"... completed job in {time.time() - start} seconds\")\nprint(\"Average out-degree: \", full_results[1])\nprint(\"Top 10 nodes (by out-degree:)\\n\", full_results[0])\nprint(\"SampledCounts\", full_results[2])\nplt.hist(full_results[2], bins=50)\nplt.title(\"Distribution of Out-Degree\")\nplt.show()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">... completed job in 57.72919535636902 seconds\nAverage out-degree:  24.58172086160701\nTop 10 nodes (by out-degree:)\n [(&#39;7883280&#39;, 7132), (&#39;7884831&#39;, 5877), (&#39;6075450&#39;, 5875), (&#39;6074992&#39;, 5855), (&#39;7828359&#39;, 5839), (&#39;7880980&#39;, 5692), (&#39;1008643&#39;, 5598), (&#39;7828391&#39;, 5597), (&#39;7873008&#39;, 5573), (&#39;7841582&#39;, 5530)]\nSampledCounts [19, 89, 25, 12, 9, 52, 13, 22, 11, 1, 19, 19, 6, 1, 1, 1, 20, 11, 15, 16, 3, 7, 75, 7, 5, 25, 12, 3, 14, 1, 3, 1, 61, 19, 133, 11, 27, 12, 16, 7, 7, 5, 11, 4, 66, 1, 3, 13, 1, 15, 2, 35, 5, 73, 1, 13, 13, 58, 10, 26, 14, 22, 3, 24, 5, 1953, 275, 10, 10, 9, 26, 1, 4, 63, 67, 34, 58, 26, 44, 1, 23, 5, 1, 1, 92, 78, 11, 1, 3, 15, 10, 19, 65, 76, 21, 26, 8, 21, 19, 6, 26, 27, 1, 14, 1, 9, 1, 4, 28, 1, 11, 13, 7, 12, 5, 7, 15, 3, 5, 36, 37, 45, 1, 6, 1, 58, 13, 8, 22, 18, 6, 50, 2, 11, 1, 5, 9, 43, 139, 20, 57, 13, 83, 38, 12, 33, 19, 10, 19, 31, 13, 8, 18, 11, 7, 18, 7, 29, 12, 315, 3, 1, 1, 5, 2, 21, 33, 1, 9, 11, 11, 54, 7, 12, 1, 43, 28, 1, 98, 22, 1, 1, 83, 1, 13, 11, 21, 13, 8, 11, 112, 26, 8, 4, 22, 20, 6, 5, 6, 15, 4, 164, 1, 11, 1, 27, 35, 8, 14, 35, 5, 30, 27, 9, 1, 1, 14, 1, 51, 157, 10, 16, 23, 3, 6, 1, 25, 12, 81, 21, 9, 3, 19, 42, 17, 50, 35, 21, 10, 1, 6, 37, 9, 2, 13, 17, 11, 1, 5, 127, 1, 28, 11, 7, 35, 11, 14, 9, 2, 30, 19, 13, 1, 54, 15, 98, 15, 12, 29, 11, 15, 7, 1, 46, 18, 148, 105, 53, 41, 6, 176, 20, 2, 11, 179, 5, 13, 262, 32, 325, 31, 1, 59, 12, 18, 25, 19, 37, 7, 23, 21, 12, 26, 5, 14, 10, 1, 33, 11, 2, 20, 6, 1, 15, 22, 4, 3, 7, 22, 19, 4, 5, 9, 23, 9, 29, 72, 133, 11, 53, 66, 20, 12, 20, 17, 33, 19, 37, 2, 31, 14, 14, 9, 1, 89, 31, 1, 2, 22, 55, 1, 29, 15, 24, 9, 1, 13, 18, 18, 52, 8, 41, 9, 14, 15, 1, 1, 13, 9, 4, 10, 16, 1, 31, 1, 1, 10, 20, 24, 25, 20, 6, 20, 6, 40, 32, 19, 1, 28, 17, 1, 12, 10, 16, 1, 12, 14, 16, 1, 9, 34, 1, 130, 17, 30, 24, 22, 2, 34, 14, 22, 14, 21, 17, 39, 13, 1, 34, 31, 11, 1, 17, 1, 4, 41, 1, 61, 25, 13, 56, 43, 33, 14, 11, 17, 62, 28, 107, 23, 19, 7, 49, 5, 21, 27, 6, 1, 110, 1, 8, 10, 1, 7, 4, 1, 7, 1, 15, 14, 12, 6, 17, 7, 4, 45, 7, 1, 21, 19, 9, 1, 78, 22, 3, 34, 11, 1, 6, 27, 1, 13, 10, 64, 8, 22, 27, 6, 1, 31, 96, 45, 1, 26, 2, 40, 7, 18, 1, 1, 13, 25, 1, 4, 2, 18, 15, 81, 8, 15, 1, 1, 12, 1, 1, 8, 17, 23, 7, 169, 5, 22, 2, 5, 54, 17, 9, 7, 6, 6, 4, 11, 1, 10, 12, 10, 12, 10, 14, 68, 1, 3, 1, 4, 19, 3, 47, 162, 38, 131, 18, 12, 11, 8, 27, 170, 42, 4, 1, 8, 43, 24, 13, 6, 1, 26, 68, 84, 28, 2, 138, 13, 23, 3, 20, 22, 13, 37, 19, 2, 9, 12, 98, 1, 29, 1, 58, 56, 19, 35, 1, 331, 91, 56, 102, 23, 41, 19, 20, 1, 9, 13, 9, 56, 123, 3, 11, 27, 294, 6, 20, 21, 48, 2, 6, 1, 22, 31, 159, 5, 12, 1, 9, 36, 5, 6, 7, 1, 179, 48, 11, 71, 1, 70, 72, 9, 1, 11, 22, 7, 12, 15, 42, 29, 4, 70, 52, 24, 19, 28, 1, 6, 13, 115, 189, 32, 125, 11, 2, 9, 48, 11, 10, 8, 10, 22, 1, 97, 7, 5, 1, 34, 14, 102, 19, 1, 14, 1, 7, 6, 1, 19, 1, 1, 1, 7, 1, 7, 6, 32, 9, 52, 17, 32, 9, 1, 7, 20, 32, 88, 20, 214, 29, 5, 60, 8, 30, 17, 10, 1, 16, 12, 13, 31, 92, 8, 28, 168, 18, 19, 1, 6, 7, 3, 5, 7, 3, 10, 10, 12, 76, 10, 2, 1, 4, 1, 17, 30, 7, 5, 29, 17, 21, 341, 1, 6, 10, 13, 6, 45, 34, 10, 12, 1, 16, 39, 27, 93, 16, 17, 4, 19, 31, 10, 3, 11, 157, 2, 6, 6, 16, 30, 16, 19, 3, 3, 62, 114, 11, 43, 21, 7, 8, 19, 75, 1, 30, 5, 1, 12, 3, 5, 21, 1, 22, 12, 1, 1, 42, 42, 9, 16, 4, 9, 7, 4, 1, 13, 1, 38, 4, 51, 6, 7, 1, 8, 18, 211, 1, 27, 27, 9, 13, 5, 1, 36, 13, 6, 14, 13, 27, 22, 45, 13, 6, 3, 483, 1, 10, 3, 10, 20, 98, 96, 26, 9, 19, 1, 28, 15, 7, 3, 1, 110, 13, 11, 1, 5, 15, 25, 118, 3, 10, 9, 1, 4, 8, 11, 9, 147, 1, 20, 51, 1, 18, 1, 35, 24, 42, 478, 11, 11, 25, 10, 8, 12, 29, 49, 15, 1, 13, 1, 10, 24, 17, 19, 1, 8, 14, 1, 8, 8, 4, 1, 108, 103, 1, 15, 13, 1, 7, 66, 34, 38, 22, 6, 168, 13, 1, 14, 11, 8, 7, 164, 1, 50, 43, 13, 10, 1, 45, 257, 1, 6, 7, 1, 51, 6, 6, 6, 18, 13, 17, 13, 21, 17, 59, 36, 23, 14, 15, 38, 30, 10, 31, 1, 5, 16, 2, 23, 6, 5, 14, 29, 11, 13, 6, 4, 484, 1, 25, 34, 17, 12, 138, 28, 14, 1, 1, 9, 15, 1, 17, 7, 31, 24, 36, 1, 3, 141, 21, 14, 1, 8, 88, 60, 18, 6, 11, 1, 9]\n</div>"]}}],"execution_count":49},{"cell_type":"markdown","source":["# Question 7 - PageRank part 1 (Initialize the Graph)\n\nOne of the challenges of performing distributed graph computation is that you must pass the entire graph structure through each iteration of your algorithm. As usual, we seek to design our computation so that as much work as possible can be done using the contents of a single record. In the case of PageRank, we'll need each record to include a node, its list of neighbors and its (current) rank. In this question you'll initialize the graph by creating a record for each dangling node and by setting the initial rank to 1/N for all nodes. \n\n__`NOTE:`__ Your solution should _not_ hard code **N**.\n\n### Q7 Tasks:\n* __a) short response:__ What is **N**? Use the analogy of the infinite random web-surfer to explain why we'll initialize each node's rank to 1/N. (i.e. what is the probabilistic interpretation of this choice?)\n\n* __b) short response:__ Will it be more efficient to compute **N** before initializing records for each dangling node or after? Explain your reasoning.\n\n* __c) code:__ Fill in the missing code below to create a Spark job that:\n  * parses each input record\n  * creates a new record for any dangling nodes and sets it list of neighbors to be an empty collection\n  * initializes a rank of 1/N for each node\n  * returns a pair RDD with records in the format specified by the docstring\n\n\n* __d) code:__ Run the provided code to confirm that your job in `part a` has a record for each node and that your should records match the format specified in the docstring and the count should match what you computed in question 5. [__`TIP:`__ _you might want to take a moment to write out what the expected output should be fore the test graph, this will help you know your code works as expected_]\n \n__`NOTE:`__ Please observe scalability best practices in the design of your code & comment your work clearly. You will be graded on both the clarity and the design."],"metadata":{}},{"cell_type":"markdown","source":["### Q7 Student Answers:\n\n> __a)__ Type your answer here! \n\n> __b)__ Type your answer here!"],"metadata":{}},{"cell_type":"code","source":["# part c - job to initialize the graph (RUN THIS CELL AS IS)\ndef initGraph(dataRDD):\n    \"\"\"\n    Spark job to read in the raw data and initialize an \n    adjacency list representation with a record for each\n    node (including dangling nodes).\n    \n    Returns: \n        graphRDD -  a pair RDD of (node_id , (score, edges))\n        \n    NOTE: The score should be a float, but you may want to be \n    strategic about how format the edges... there are a few \n    options that can work. Make sure that whatever you choose\n    is sufficient for Question 8 where you'll run PageRank.\n    \"\"\"\n    ############## YOUR CODE HERE ###############\n\n    # write any helper functions here\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    # write your main Spark code here\n    \n    \n    \n    \n    \n    ############## (END) YOUR CODE ##############\n    \n    return graphRDD"],"metadata":{},"outputs":[],"execution_count":52},{"cell_type":"code","source":["# part c - run your Spark job on the test graph (RUN THIS CELL AS IS)\nstart = time.time()\ntestGraph = initGraph(testRDD).collect()\nprint(f'... test graph initialized in {time.time() - start} seconds.')\ntestGraph"],"metadata":{},"outputs":[],"execution_count":53},{"cell_type":"code","source":["# part c - run your code on the main graph (RUN THIS CELL AS IS)\nstart = time.time()\nwikiGraphRDD = initGraph(wikiRDD)\nprint(f'... full graph initialized in {time.time() - start} seconds')"],"metadata":{},"outputs":[],"execution_count":54},{"cell_type":"code","source":["# part c - confirm record format and count (RUN THIS CELL AS IS)\nstart = time.time()\nprint(f'Total number of records: {wikiGraphRDD.count()}')\nprint(f'First record: {wikiGraphRDD.take(1)}')\nprint(f'... initialization continued: {time.time() - start} seconds')"],"metadata":{},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":["# Question 8 - PageRank part 2 (Iterate until convergence)\n\nFinally we're ready to compute the page rank. In this last question you'll write a Spark job that iterates over the initialized graph updating each nodes score until it reaches a convergence threshold. The diagram below gives a visual overview of the process using a 5 node toy graph. Pay particular attention to what happens to the dangling mass at each iteration.\n\n<img src='https://github.com/kyleiwaniec/w261_assets/blob/master/images/HW5/PR-illustrated.png?raw=true' width=50%>\n\n\n\n__`A Note about Notation:`__ The formula above describes how to compute the updated page rank for a node in the graph. The $P$ on the left hand side of the equation is the new score, and the $P$ on the right hand side of the equation represents the accumulated mass that was re-distributed from all of that node's in-links. Finally, $|G|$ is the number of nodes in the graph (which we've elsewhere refered to as $N$).\n\n### Q8 Tasks:\n* __a) short response:__ In terms of the infinite random walk analogy, interpret the meaning of the first term in the PageRank calculation: $\\alpha * \\frac{1}{|G|}$\n\n* __b) short response:__ In the equation for the PageRank calculation above what does $m$ represent and why do we divide it by $|G|$?\n\n* __c) short response:__ Keeping track of the total probability mass after each update is a good way to confirm that your algorithm is on track. How much should the total mass be after each iteration?\n\n* __d) code:__ Fill in the missing code below to create a Spark job that take the initialized graph as its input then iterates over the graph and for each pass:\n  * reads in each record and redistributes the node's current score to each of its neighbors\n  * uses an accumulator to add up the dangling node mass and redistribute it among all the nodes. (_Don't forget to reset this accumulator after each iteration!_)\n  * uses an accumulator to keep track of the total mass being redistributed.( _This is just for your own check, its not part of the PageRank calculation. Don't forget to reset this accumulator after each iteration._)\n  * aggregates these partial scores for each node\n  * applies telportation and damping factors as described in the formula above.\n  * combine all of the above to compute the PageRank as described by the formula above.\n  * \n  \n   __WARNING:__ Some pages contain multiple hyperlinks to the same destination, please take this into account when redistributing the mass.\n\n \n__`NOTE:`__ Please observe scalability best practices in the design of your code & comment your work clearly. You will be graded on both the clarity and the design."],"metadata":{}},{"cell_type":"markdown","source":["### Q8 Student Answers:\n\n> __a)__ Type your answer here!\n\n> __b)__ Type your answer here! \n\n> __c)__ Type your answer here!"],"metadata":{}},{"cell_type":"code","source":["# part d - provided FloatAccumulator class (RUN THIS CELL AS IS)\n\nfrom pyspark.accumulators import AccumulatorParam\n\nclass FloatAccumulatorParam(AccumulatorParam):\n    \"\"\"\n    Custom accumulator for use in page rank to keep track of various masses.\n    \n    IMPORTANT: accumulators should only be called inside actions to avoid duplication.\n    We stringly recommend you use the 'foreach' action in your implementation below.\n    \"\"\"\n    def zero(self, value):\n        return value\n    def addInPlace(self, val1, val2):\n        return val1 + val2"],"metadata":{},"outputs":[],"execution_count":58},{"cell_type":"code","source":["# part d - job to run PageRank (RUN THIS CELL AS IS)\ndef runPageRank(graphInitRDD, alpha = 0.15, maxIter = 10, verbose = True):\n    \"\"\"\n    Spark job to implement page rank\n    Args: \n        graphInitRDD  - pair RDD of (node_id , (score, edges))\n        alpha         - (float) teleportation factor\n        maxIter       - (int) stopping criteria (number of iterations)\n        verbose       - (bool) option to print logging info after each iteration\n    Returns:\n        steadyStateRDD - pair RDD of (node_id, pageRank)\n    \"\"\"\n    # teleportation:\n    a = sc.broadcast(alpha)\n    \n    # damping factor:\n    d = sc.broadcast(1-a.value)\n    \n    # initialize accumulators for dangling mass & total mass\n    mmAccum = sc.accumulator(0.0, FloatAccumulatorParam())\n    totAccum = sc.accumulator(0.0, FloatAccumulatorParam())\n    \n    ############## YOUR CODE HERE ###############\n    \n    # write your helper functions here, \n    # please document the purpose of each clearly \n    # for reference, the master solution has 5 helper functions.\n\n\n            \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n        \n    # write your main Spark Job here (including the for loop to iterate)\n    # for reference, the master solution is 21 lines including comments & whitespace\n\n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ############## (END) YOUR CODE ###############\n    \n    return steadyStateRDD"],"metadata":{},"outputs":[],"execution_count":59},{"cell_type":"code","source":["# part d - run PageRank on the test graph (RUN THIS CELL AS IS)\n# NOTE: while developing your code you may want turn on the verbose option\nnIter = 20\ntestGraphRDD = initGraph(testRDD)\nstart = time.time()\ntest_results = runPageRank(testGraphRDD, alpha = 0.15, maxIter = nIter, verbose = False)\nprint(f'...trained {nIter} iterations in {time.time() - start} seconds.')\nprint(f'Top 20 ranked nodes:')\ntest_results.takeOrdered(20, key=lambda x: - x[1])"],"metadata":{},"outputs":[],"execution_count":60},{"cell_type":"markdown","source":["__`expected results for the test graph:`__\n```\n[(2, 0.3620640495978871),\n (3, 0.333992700474142),\n (5, 0.08506399429624555),\n (4, 0.06030963508473455),\n (1, 0.04255740809817991),\n (6, 0.03138662354831139),\n (8, 0.01692511778009981),\n (10, 0.01692511778009981),\n (7, 0.01692511778009981),\n (9, 0.01692511778009981),\n (11, 0.01692511778009981)]\n```"],"metadata":{}},{"cell_type":"code","source":["# part d - run PageRank on the full graph (RUN THIS CELL AS IS)\n# NOTE: wikiGraphRDD should have been computed & cached above!\nnIter = 10\nstart = time.time()\nfull_results = runPageRank(wikiGraphRDD, alpha = 0.15, maxIter = nIter, verbose = True)\nprint(f'...trained {nIter} iterations in {time.time() - start} seconds.')\nprint(f'Top 20 ranked nodes:')\nfull_results.takeOrdered(20, key=lambda x: - x[1])"],"metadata":{},"outputs":[],"execution_count":62},{"cell_type":"code","source":["# title\\t indx\\t inDeg\\t outDeg\nindexRDD.take(1)"],"metadata":{},"outputs":[],"execution_count":63},{"cell_type":"code","source":["namesKV_RDD = indexRDD.map(lambda x: (int(x.split('\\t')[1]), x.split('\\t')[0]))"],"metadata":{},"outputs":[],"execution_count":64},{"cell_type":"code","source":["namesKV_RDD.take(1)"],"metadata":{},"outputs":[],"execution_count":65},{"cell_type":"code","source":["# We should have saved these above, but it takes too long to run in the cloud ($$$), so for expedience:\ntop_20 = [(13455888, 0.0015447247129832947),\n (4695850, 0.0006710240718906518),\n (5051368, 0.0005983856809747697),\n (1184351, 0.0005982073536467391),\n (2437837, 0.0004624928928940748),\n (6076759, 0.00045509400641448284),\n (4196067, 0.0004423778888372447),\n (13425865, 0.00044155351714348035),\n (6172466, 0.0004224002001845032),\n (1384888, 0.0004012895604073632),\n (6113490, 0.00039578924771805474),\n (14112583, 0.0003943847283754762),\n (7902219, 0.000370098784735699),\n (10390714, 0.0003650264964328283),\n (12836211, 0.0003619948863114985),\n (6237129, 0.0003519555847625285),\n (6416278, 0.00034866235645266493),\n (13432150, 0.00033936510637418247),\n (1516699, 0.00033297500286244265),\n (7990491, 0.00030760906265869104)]"],"metadata":{},"outputs":[],"execution_count":66},{"cell_type":"code","source":["top_20_RDD = sc.parallelize(top_20)"],"metadata":{},"outputs":[],"execution_count":67},{"cell_type":"code","source":["top_20_RDD.take(1)"],"metadata":{},"outputs":[],"execution_count":68},{"cell_type":"markdown","source":["# Extra Credit\n(The combined extra credit points amount to approximately 5 percentage points on your final grade.)\n\n## EC 1 - 5pts\nThe indexRDD we created earlier from the indices.txt file contains the titles of the pages and thier IDs.\n\n* __a) code:__ Join this dataset with your top 20 results.\n* __b) code:__ Print the results"],"metadata":{}},{"cell_type":"markdown","source":["## Join with indexRDD and print pretty"],"metadata":{}},{"cell_type":"code","source":["# part a\njoinedWithNames = None\n############## YOUR CODE HERE ###############\n\n############## END YOUR CODE ###############"],"metadata":{},"outputs":[],"execution_count":71},{"cell_type":"code","source":["# part b\n# Feel free to modify this cell to suit your implementation, but please keep the formatting and sort order.\nprint(\"{:10s}\\t| {:10s}\\t| {}\".format(\"PageRank\",\"Page id\",\"Title\"))\nprint(\"=\"*100)\nfor r in joinedWithNames:\n    print (\"{:6f}\\t| {:10d}\\t| {}\".format(r[1][1],r[0],r[1][0]))"],"metadata":{},"outputs":[],"execution_count":72},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":73},{"cell_type":"markdown","source":["## GraphFrames\n## EC 2 - 30pts\nGraphFrames is a graph library which is built on top of the Spark DataFrames API.\n\n* __a) code:__ Using the same dataset, run the graphframes implementation of pagerank.\n* __b) code:__ Join the top 20 results with indices.txt and display in the same format as above.\n* __c) short answer:__ Compare your results with the results from graphframes.\n\n__NOTE:__ Feel free to create as many code cells as you need. Code should be clear and concise - do not include your scratch work. Comment your code if it's not self annotating."],"metadata":{}},{"cell_type":"code","source":["from graphframes import *"],"metadata":{},"outputs":[],"execution_count":75},{"cell_type":"code","source":["from pyspark.sql import functions as F"],"metadata":{},"outputs":[],"execution_count":76},{"cell_type":"code","source":["# load the data into Spark RDDs for convenience of use later (RUN THIS CELL AS IS)\ntestRDD = sc.textFile('gs://w261-bucket/wiki/test_graph.txt')\nindexRDD = sc.textFile('gs://w261-bucket/wiki/indices.txt')\nwikiRDD = sc.textFile('gs://w261-bucket/wiki/wiki_graph.txt')"],"metadata":{},"outputs":[],"execution_count":77},{"cell_type":"code","source":["DF = wikiRDD.map(lambda x: (x.split('\\t')[0], ast.literal_eval(x.split('\\t')[1]))).toDF()"],"metadata":{},"outputs":[],"execution_count":78},{"cell_type":"code","source":["%%time\nDF.take(1)"],"metadata":{},"outputs":[],"execution_count":79},{"cell_type":"code","source":["%%time\nv = DF.select('_1').withColumnRenamed('_1','id').distinct()"],"metadata":{},"outputs":[],"execution_count":80},{"cell_type":"code","source":["%%time\nv.cache()"],"metadata":{},"outputs":[],"execution_count":81},{"cell_type":"code","source":["%%time\nv.show(1)"],"metadata":{},"outputs":[],"execution_count":82},{"cell_type":"code","source":["import ast\ndef getEdges(row):\n    node_id, nodes = row\n    for node in nodes: \n        yield int(node_id), int(node)"],"metadata":{},"outputs":[],"execution_count":83},{"cell_type":"code","source":["%%time\ne = spark.createDataFrame(DF.rdd.flatMap(getEdges), [\"src\", \"dst\"])"],"metadata":{},"outputs":[],"execution_count":84},{"cell_type":"code","source":["%%time\ne.cache()"],"metadata":{},"outputs":[],"execution_count":85},{"cell_type":"code","source":["%%time\ne.show(1)"],"metadata":{},"outputs":[],"execution_count":86},{"cell_type":"code","source":["%%time\n# Create a GraphFrame\nfrom graphframes import *\ng = GraphFrame(v, e)\n\n# Query: Get in-degree of each vertex.\n# g.inDegrees.show()"],"metadata":{},"outputs":[],"execution_count":87},{"cell_type":"code","source":["%%time\n# Run PageRank algorithm, and show results.\nresults = g.pageRank(resetProbability=0.15, maxIter=10)"],"metadata":{},"outputs":[],"execution_count":88},{"cell_type":"code","source":["%%time\ntop_20 = results.vertices.orderBy(F.desc(\"pagerank\")).limit(20)"],"metadata":{},"outputs":[],"execution_count":89},{"cell_type":"code","source":["%%time\ntop_20.show()"],"metadata":{},"outputs":[],"execution_count":90},{"cell_type":"code","source":["type(top_20)"],"metadata":{},"outputs":[],"execution_count":91},{"cell_type":"code","source":["top_20.take(1)"],"metadata":{},"outputs":[],"execution_count":92},{"cell_type":"code","source":["%%time\nnamesKV_RDD = indexRDD.map(lambda x: (int(x.split('\\t')[1]), x.split('\\t')[0]))"],"metadata":{},"outputs":[],"execution_count":93},{"cell_type":"code","source":["namesKV_DF = namesKV_RDD.toDF()"],"metadata":{},"outputs":[],"execution_count":94},{"cell_type":"code","source":["namesKV_DF = namesKV_DF.withColumnRenamed('_1','id')\nnamesKV_DF = namesKV_DF.withColumnRenamed('_2','title')\nnamesKV_DF.take(1)"],"metadata":{},"outputs":[],"execution_count":95},{"cell_type":"code","source":["%%time\nresultsWithNames = namesKV_DF.join(top_20, namesKV_DF.id==top_20.id).orderBy(F.desc(\"pagerank\")).collect()"],"metadata":{},"outputs":[],"execution_count":96},{"cell_type":"code","source":["# TODO: use f' for string formatting\nprint(\"{:10s}\\t| {:10s}\\t| {}\".format(\"PageRank\",\"Page id\",\"Title\"))\nprint(\"=\"*100)\nfor r in resultsWithNames:\n    print (\"{:6f}\\t| {:10s}\\t| {}\".format(r[3],r[2],r[1]))"],"metadata":{},"outputs":[],"execution_count":97},{"cell_type":"markdown","source":["Our RDD implementaion takes about 35 minutes, whereas the GraphFrame one takes around 8 minutes. GraphFrames doesn't normalize the ranks."],"metadata":{}},{"cell_type":"markdown","source":["### Congratulations, you have completed HW5! Please refer to the readme for submission instructions.\n\nIf you would like to provide feedback regarding this homework, please use the survey at: https://docs.google.com/forms/d/e/1FAIpQLScgIz4laP2JHChStLZx8MO0jGvrGyrOyQBnj7M4_4vcVXkB7g/viewform?usp=sf_link"],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":100}],"metadata":{"name":"hw5_Workbook.ipynb","notebookId":2385172796115718},"nbformat":4,"nbformat_minor":0}